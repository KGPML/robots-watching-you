import json
import skipthoughts

with open('vis1.json') as data_file:    #Open the input file
    data = json.load(data_file)

X = {}                  #Define dictionary X
for element in data:
      
     X[str(element['image_id'])] = str(element['caption'])    #Key are image id and value are captions


model = skipthoughts.load_model()
Y = {}                                          #Define dictionary Y, keys are image id's and values the vectors for each sentence
#Y = skipthoughts.encode(model,X.values())      
for i in X:                                    #This for loop encodes individaul sentence into vectors. But this gives floating point error(core dumped)
    Y[i] = skipthoughts.encode(model,X[i])   

db = DBSCAN(eps=0.3, min_samples=200).fit(Y.values())    #This is the function for density based clustering of the vectors
core_samples_mask = np.zeros_like(db.labels_, dtype=bool)    
core_samples_mask[db.core_sample_indices_] = True
labels = db.labels_
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
print('Estimated number of clusters: %d' % n_clusters_)        #Just to see how many clusters are formed.
outliers = Y.values()[labels == -1]   #These are the outliers that is the anomalies
for i in Y:                           #Comparing the vectors in Y to every vector in outliers. If a vector in Y matches then it is an anomaly and it should print the key that is image id.
     for element in outliers:
          if (Y[i] == element):
                print i
